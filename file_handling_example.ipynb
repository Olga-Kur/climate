{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4jvKOW+k0OhUsGaFx2+wl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PlaZMaD/climate/blob/main/file_handling_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подключаем ВАШ гугл-диск, как папку. В примере у меня в корне моего диска есть папка weather_data, где лежит файл boloto_2016.xlsx"
      ],
      "metadata": {
        "id": "2GWEPYB5SIen"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taO2EHOFQT84"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from google.colab import drive\n",
        "import os\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Это наши функции, которые мы будем применять."
      ],
      "metadata": {
        "id": "QFpCZ9EOSkUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def hampel_filter_pandas(input_series, window_size, n_sigmas=3):\n",
        "    k = 1.4826  # scale factor for Gaussian distribution\n",
        "    new_series = input_series.copy()\n",
        "    indices = None\n",
        "    # # helper lambda function\n",
        "    MAD = lambda x: np.median(np.abs(x - np.median(x)))\n",
        "\n",
        "    rolling_median = input_series.rolling(window=2 * window_size, center=True).median()\n",
        "    rolling_mad = k * input_series.rolling(window=2 * window_size, center=True).apply(MAD)\n",
        "    diff = np.abs(input_series - rolling_median)\n",
        "    print(len(diff.index), len(rolling_mad.index))\n",
        "\n",
        "    indices = diff > (n_sigmas * rolling_mad)  # list(np.argwhere(diff > (n_sigmas * rolling_mad)).flatten())\n",
        "    # #new_series[indices] = rolling_median[indices]\n",
        "\n",
        "    return new_series, indices[indices == True].index\n",
        "\n",
        "def mad_filter(input_df, target_col, z=5.5, fill_method='new'):\n",
        "    data_if = input_df[[target_col]].copy()\n",
        "    data_if['rolling_fill'] = data_if[target_col].rolling(10).mean()\n",
        "    data_if['plus_shift'] = data_if[target_col].shift(1)\n",
        "    null_index_plus = data_if['plus_shift'].isnull()\n",
        "    null_index_plus = null_index_plus[null_index_plus == True].index\n",
        "\n",
        "    data_if['minus_shift'] = data_if[target_col].shift(-1)\n",
        "    null_index_minus = data_if['minus_shift'].isnull()\n",
        "    null_index_minus = null_index_minus[null_index_minus == True].index\n",
        "\n",
        "    if fill_method == 'old':\n",
        "        data_if.loc[null_index_plus, 'plus_shift'] = data_if.loc[null_index_plus, target_col]\n",
        "        data_if.loc[null_index_minus, 'minus_shift'] = data_if.loc[null_index_minus, target_col]\n",
        "    else:\n",
        "        data_if.loc[null_index_plus, 'plus_shift'] = data_if.loc[null_index_plus, 'rolling_fill']\n",
        "        data_if.loc[null_index_minus, 'minus_shift'] = data_if.loc[null_index_minus, 'rolling_fill']\n",
        "\n",
        "    data_if['d_i'] = (data_if[target_col] - data_if['minus_shift']) - (data_if['plus_shift'] - data_if[target_col])\n",
        "\n",
        "    # print(key, pd.isna(data['d_i']).value_counts())\n",
        "    d_median = np.median(data_if.query('not (d_i != d_i)')['d_i'])\n",
        "    MAD = np.median(np.abs(data_if.query('not (d_i != d_i)')['d_i'] - d_median))\n",
        "\n",
        "    down_threshold = d_median - (z * MAD / 0.6745)\n",
        "    up_threshold = d_median + (z * MAD / 0.6745)\n",
        "\n",
        "    out_data = np.logical_or(data_if['d_i'] < down_threshold, data_if['d_i'] > up_threshold, data_if['d_i'].isna())\n",
        "    return out_data"
      ],
      "metadata": {
        "id": "0sDZYOKBtNhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверяем, что наша папка существует, как и файл в ней."
      ],
      "metadata": {
        "id": "BBxoN4edSrO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls /content/drive/MyDrive/weather_data"
      ],
      "metadata": {
        "id": "OQlAKjy2j-x-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1uCL0X9sdmMVz4Fyw2mohlNCsQAjifvDy"
      ],
      "metadata": {
        "id": "ct6_fCXVSx6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Указываем как называется колонка, с которой будем работать и путь до файла"
      ],
      "metadata": {
        "id": "KUfDjLQ7SyPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = 'NEE'#'co2_flux_full output'\n",
        "# fileName = 'weather_data/for_filtering.xlsx'\n",
        "fileName = for_filtering.xlsx"
      ],
      "metadata": {
        "id": "19oBjZnijlX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем наш файл, если в нем несколько листов - сливаем в один."
      ],
      "metadata": {
        "id": "YnV6CMr4S-dY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = pd.read_excel(os.path.join(\"/content/drive/MyDrive/\", fileName),\n",
        "                         sheet_name=None,          # загружаем все листы! Если надо конкретные, можно их прописать тут\n",
        "                         skiprows=None)#lambda x: x==1)  # Важный момент! В моем файле вторая строка идет без данных, поэтому я ее вот таким образом пропускаю, уберите эту опцию, если у вас все идет подряд.\n",
        "data = pd.concat(all_data.values(), ignore_index=True)"
      ],
      "metadata": {
        "id": "CfHQEo-tRC5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.head())"
      ],
      "metadata": {
        "id": "mKXpMqU4q91W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тут самое сложное. Надо нормально прочитать временнЫе метки, а они у всех файлов что мне показывали -  разные. В итоге нужна колонка, в которой как-то будут указаны целиком дата и время. Если она есть - отлично, если нет - формируем сами из нескольких имеющихся."
      ],
      "metadata": {
        "id": "aARC14aCUkB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data['dateTime'] = data['dateTime'].astype(str)\n",
        "# data = data.rename(columns={'Unnamed: 0': \"dateTime\"})\n",
        "# data['dateTime'] = pd.to_datetime(data['dateTime'],\n",
        "#                                   format='%d.%m.%Y %H:%M:%S') #это шаблон того, как у нас выглядят наши данные.\n",
        "# data.index = pd.DatetimeIndex(data['dateTime'])\n",
        "\n",
        "\n",
        "\n",
        "# data = data.rename(columns={'Unnamed: 0': \"dateTime\"})\n",
        "data['dateTime'] = pd.to_datetime(data['timestamp'],\n",
        "                                  format='%Y-%m-%d %H:%M:%S') #это шаблон того, как у нас выглядят наши данные.\n",
        "data.index = pd.DatetimeIndex(data['dateTime'])"
      ],
      "metadata": {
        "id": "uBfEkgZtUYzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Помечаем строки с данными."
      ],
      "metadata": {
        "id": "dHgkJCGrZ9mR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['process_flag'] = np.invert(pd.isnull(data[target]))"
      ],
      "metadata": {
        "id": "x-1L_y6DUJhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Начинаем искать выбросы разными методами..."
      ],
      "metadata": {
        "id": "wf6RMr8aaCd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[data['process_flag']==True, 'filter_55'] = mad_filter(data.query('process_flag==True'), target, z=5.5, fill_method='new')\n",
        "fig = px.scatter(data, x='dateTime', y=target, color='filter_55', title='co2 MAD z=7')\n",
        "# fig.write_html(f\"/content/drive/MyDrive/weather_data/co2_plot.html\")\n",
        "fig.update_yaxes(type=\"log\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Xc6NTJyIUl94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[data['process_flag']==True, 'filter_7'] = mad_filter(data.query('process_flag==True'), target, z=7., fill_method='new')\n",
        "fig = px.scatter(data, x='dateTime', y=target, color='filter_7', title='co2 MAD z=7')\n",
        "# fig.write_html(f\"/content/drive/MyDrive/weather_data/co2_plot.html\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "vt4nCkgE68xE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['filter_hampel'] = False\n",
        "rwn, indices = hampel_filter_pandas(data.query('process_flag==True')[target], window_size=10)\n",
        "data.loc[indices, 'filter_hampel'] = True\n",
        "fig = px.scatter(data.query('process_flag==True'), x='dateTime', y=target, color='filter_hampel', title='co2 Hampel')\n",
        "# fig.write_html(f\"/content/drive/MyDrive/weather_data/{key}_plot.html\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "-ruSCDDjeGkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['filter_hampel_OR_55'] = np.logical_or(data['filter_hampel'],data['filter_55'])\n",
        "fig = px.scatter(data.query('process_flag==True'), x='dateTime', y=target, color='filter_hampel_OR_55', title='co2 or 55')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "UDtMt3E3Bwtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['filter_hampel_after_55'] = False\n",
        "rwn, indices = hampel_filter_pandas(data.query('process_flag==True & filter_55==False')[target], window_size=10)\n",
        "data.loc[indices, 'filter_hampel_after_55'] = True\n",
        "data['filter_hampel_after_55'] = np.logical_or(data['filter_hampel_after_55'], data['filter_55'])\n",
        "fig = px.scatter(data.query('process_flag==True'), x='dateTime', y=target, color='filter_hampel_after_55', title='co2 Hampel after MAD 5.5')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "JwI6YWprBlwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если надо - сохраняем наши данные в файл."
      ],
      "metadata": {
        "id": "74KoG-ppaTmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir, out_filename =  os.path.split(os.path.join(\"/content/drive/MyDrive/\", fileName))\n",
        "out_filename = \"out_\"+out_filename\n",
        "data.to_csv(os.path.join(base_dir, out_filename))\n"
      ],
      "metadata": {
        "id": "3CBZqBydeb05"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}